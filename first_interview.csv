,question,answer
0,Could you please introduce yourself and provide a brief overview of your background in data science?,"I am Ali Zolfagharian. I received my PhD three years ago at the university of Konstanz and I worked as data scientist for three years, contributing in project, teaching, and contributing in making course and programs, and certainly doing research on machine learning, and data visualization. I am also certified data science associate in microsoft. I did multiple projects, from image processing to NLP and I will be happy to provide more information. Regarding my personal life, I do cycling and music is also my main hobby."
1,"I'm curious about the projects you've worked on. Could you highlight one or two projects that you found particularly challenging or interesting, and walk me through the problem-solving process you applied?","I could mention three projects. First was NLP project to make automated grading for students answer in a written exam. What I did was using similarity index using BERT large language model and compare student answer with teacher sample answer in terms of their cosine similarity useing sklearn. Seconr project, was about image processing. We have 55000 image with bbox and segmentation, and we trained decetron object detection model, to get ingridient of a food based on an image. It was successful in terms of ingredient, there were some issue like whether the tomato in food is cooked or raw etc. It was important because the aim of the project was to predict the nutrition fact of the food. And thirs project, was about finance. I make a pipeline in azure to gather tick data from stock exchange api, and I made some function to evaluate the impact of asia during 22:00 till 8:00 on commodity price in london and new york based like Nasdaq.  It was a successful project in terms of providing information, prediction was plausible as it had around 70% accurate winning trade suggestion, however defining the stop loss, was important but tey wanted to do it manually."
2,"Let's delve a bit deeper into the NLP project. Could you discuss any specific challenges you faced during the automated grading project, and how you addressed or mitigated those challenges?","Regarding NLP project, automated grading project, the most challenging part was teachers grade and similarity index of BERT model. First, they were not in same interval, also BERT model does not consider a context, then evaluate similarity of two expression. Therefore, from BERT model, the similarity of student answer and teacher sample answer were much higher than teacher grade after normalizing both intervals. What I did was finding the best way to map teacher grade to BERT index, to make it more meaningful. Considering the minimum grade be teacher and mapping to a better interval. The result was plausible. For making even better tuned, after each train, the reverse map also needed some small amendment. 
Another challenge was data augmentation. We used Flan-t5 large, to reparaphrise, make summary of some reply to make more data for training."
3,"Additionally, did you encounter any ethical considerations when implementing an automated grading system, and how did you approach those?","As the grade was Automated, we gave the student chance to see through a visualization why the grade was given, also correct answer, also they had a chance to disagree, then teacher manually see the evaluation. Also before deployement, we used techniques like attention visualization to show which part of input was important for the grade"
4,"let's talk about the image processing project. You mentioned using the Detectron object detection model to identify ingredients in food images. Could you discuss any specific results or insights that you gained from the project? Additionally, were there any lessons learned or improvements you would consider for future image processing projects?","It was an amazing project. First I learned about Common Objects in Context, as each object had bounding boxes, segmentation masks, and captions. But the most interesting part was using google blob and get coco instances and data from google cloud, train the model on virtual instance with GPU. Working on image data and see new types of unstructure data after text, and how things work there was amazing. Indeed the project helped me more to learn about machine learning operation, as I made the training part and I deployed the project.  I made a docker file, and in gcp I made a container. It worked very well."
5,let's shift our focus to the finance project. You mentioned evaluating the impact of Asian trading hours on commodity prices and creating a pipeline in Azure to gather tick data. Could you provide more details on the specific features or indicators you considered in your analysis?,"I made a class for this financial analysis. Getting data, evaluatin adnassigning value of timestamp, and when the factual commodity data is coming, which stock market is open, I had column for important one like dow jones, S&P 500, Nasdaq, Nikkei, SSE composite, Hang Seng etc. Then I evaluate what is max and min value of day during asia time in 24 time interval. And after that I made a column to say when a breakout happened. Also I created a column that showd past breakout situation. Then I made a function that does a trade with x time interval to say if a trade happens in breakout what would be the result. In histogram kde, I reached to a probability distribution of trading close time. I did the same based on price. At the end both gives user the probability of having a suitable closing time, based on both function. Eventually I used rnn to make a simple prediction to compare both trading suggestion."
6,"Given the complexity of financial markets, did you encounter any specific challenges in terms of data quality, model performance, or any other unexpected issues during the project? Additionally, how did you validate the effectiveness of your trading suggestions, and were there any lessons learned from the validation process?","there were difficulty to work with time, and consistency of time, as data was from various source, wth various time zone, but overall the preprocessing was not a challenge. A surprising fact, was indeed the confirmation of a known approach in the market, that at the beggining I thought it will not work. By visualizing the price interval of 12 important markets (e.g. which are open from 10:30-13:30, 13:30-16:30 etc) I reached to the conclusion that time is not flat in the market and it is very sensitive to its distance to the openning of a new stock market. E.g. Another conclusion was to have a decision tree for trading, and it is better to make it more reliable based on times that events happends, like declairing a decision. Indeed my project, was only a help to facilitate the time consuming process of claculating and working on the visualization. It only give signal, and the decision is by user. However based on data, it increase around 5% per month, however I did not considered the commition from brooker. Overal it was plausible."
7,"on the finance project, is there anything specific you would have done differently in hindsight, or any areas you would like to explore further in future projects related to financial analysis or data science in general?","I want to complete this project to see the impact of every time interval that the number of open stockmarket are different on another one. Then I want to make weighted timestamp, or the significant of a special time in a 24 hour. Also I want to see what happens if I use non-additive probability, like Depster Shafer theory of evidence, to see whether I can get a more meaningful prediction whcih include evaluation of risk. e.g. if I can say trading now, with stop loss x, is 40% winning, and 30%losing, then I know 30% more confident I need to evaluate risk, and I have 30% uncertainty. I think that makes more sense"
8,Is there anything else you'd like to share or discuss about your data science background or projects before we conclude the interview?,"I recently acquired a microsoft data science certificate. Recently I worked more on generative AI, and specially transformers. Regarding Data visualization also I like to add that I have strong background from practical and theoretical point of view."
